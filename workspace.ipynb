{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3d8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c8e60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n",
      "None\n",
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2b526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mail                                            content\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham              Will Ì_ b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 필요없는 row 삭제\n",
    "df = df.iloc[:, 0:2]\n",
    "df.rename(columns={\"v1\": \"mail\", \"v2\": \"content\"}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6eb14a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   58 4411  144]\n",
      " [   0    0    0 ...  470    6 1929]\n",
      " [   0    0    0 ...  659  389 2988]\n",
      " ...\n",
      " [   0    0    0 ...  105  250 8919]\n",
      " [   0    0    0 ...  200   12   47]\n",
      " [   0    0    0 ...    2   61  268]]\n"
     ]
    }
   ],
   "source": [
    "# 메일 내용 토큰화, 길이 맞춤\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df[\"content\"])\n",
    "x = tokenizer.texts_to_sequences(df[\"content\"])\n",
    "x = pad_sequences(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58660269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# y 데이터를 0 1로 분류\n",
    "y = df[\"mail\"].replace({\"ham\": 0, \"spam\": 1}).to_numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "75e928d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 32)          285472    \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,585\n",
      "Trainable params: 287,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 - RNN 모델\n",
    "inputDim = len(tokenizer.word_index) + 1 # 단어장 단어 총 갯수\n",
    "embedDim = 32 # 단어 임베딩 출력 차원 수\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(inputDim, embedDim)) # 단어 임베딩을 통해 밀집 벡터로 변환\n",
    "\n",
    "# model.add(Flatten())\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) # 출력: 이진분류 = sigmoid\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"acc\"],\n",
    "    optimizer=\"adam\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "60d734e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 4s 24ms/step - loss: 0.2801 - acc: 0.9076 - val_loss: 0.0845 - val_acc: 0.9794\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0603 - acc: 0.9852 - val_loss: 0.1001 - val_acc: 0.9614\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0275 - acc: 0.9930 - val_loss: 0.0516 - val_acc: 0.9865\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0129 - acc: 0.9978 - val_loss: 0.0638 - val_acc: 0.9767\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.0074 - acc: 0.9991 - val_loss: 0.0608 - val_acc: 0.9839\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(x, y, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6af6b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# 모델 내보내기\n",
    "model.save(\"model.h5\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd93451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8acf698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "정상적인 메일입니다! - 스팸일 확률: 0.4925984889268875%\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "\n",
    "# 사기 메시지\n",
    "test_content = \"Congratulations! You can win a prize of $3,000,000 as the 1000th visitor to this site! Click this button and enter your address to claim your winnings!\"\n",
    "\n",
    "# 업무 메시지\n",
    "test_content = \"Hello, this is tom from the HR team. To prepare for the untact era, we asked for a date when we could attend the meeting in order to prepare a gradual expansion plan for working from home, but no one has responded yet, so we are requesting it again by e-mail. I would like to have a meeting sometime next Tuesday or Wednesday. If you see the mail, please reply. So have a nice day!\"\n",
    "\n",
    "test_x = tokenizer.texts_to_sequences([test_content])\n",
    "test_x = pad_sequences(test_x)\n",
    "\n",
    "res = model.predict(test_x)\n",
    "res = res[0][0]\n",
    "if round(res) == 0: # 확률을 반올림해서 판단\n",
    "    print(f\"정상적인 메일입니다! - 스팸일 확률: {res * 100}%\")\n",
    "else:\n",
    "    print(f\"스팸 메일입니다! - 스팸일 확률: {res * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
